### api_server and background image have to be rebuilt locally, please run:
# docker compose build api_server background
# docker compose up -d
IMAGE_TAG=latest

### Edit and enable this section if you use a local Unstructured provider
### An empty string will point to the cloud endpoint of the Unstructured service
UNSTRUCTURED_API_URL="http://localhost:8000/general/v0/general"

### Edit and enable this section if you use an external llama.cpp inference provider
LITELLM_MODEL_ALIAS={"openai/phi-4":"openai//home/carlo/Documenti/AI/models/phi-4-Q6_K.gguf"}

### Enable this section if your HW is old and slow
QA_TIMEOUT=1200
TF_DR_TIMEOUT_LONG=1200
TF_DR_TIMEOUT_SHORT=600
AGENT_TIMEOUT_LLM_GENERAL_GENERATION=1200
AGENT_TIMEOUT_CONNECT_LLM_GENERAL_GENERATION=1200
AGENT_TIMEOUT_LLM_INITIAL_ANSWER_GENERATION=1200
AGENT_TIMEOUT_CONNECT_LLM_INITIAL_ANSWER_GENERATION=1200
AGENT_TIMEOUT_LLM_REFINED_ANSWER_GENERATION=1200
AGENT_TIMEOUT_CONNECT_LLM_REFINED_ANSWER_GENERATION=1200
